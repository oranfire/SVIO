%YAML:1.0

#camera calibration
model_type: PINHOLE
camera_name: camera
image_width: 848
image_height: 480
distortion_parameters:
   k1: 0.0
   k2: 0.0
   p1: 0.0
   p2: 0.0
projection_parameters:
   fx: 611.4509887695312
   fy: 611.4857177734375
   cx: 433.2039794921875
   cy: 249.4730224609375

# Topics
imu_topic: "/d400/imu0"
image_topic: "/d400/color/image_raw"
dpt_img_topic: "/d400/aligned_depth_to_color/image_raw"
output_path: "/home/oran/WS/Work/SLAM/SVIO/output"

# Extrinsic parameter between IMU and Camera.
estimate_extrinsic: 0   # 0  Have an accurate extrinsic parameters. We will trust the following imu^R_cam, imu^T_cam, don't change it.
                        # 1  Have an initial guess about extrinsic parameters. We will optimize around your initial guess.
                        # 2  Don't know anything about extrinsic parameters. You don't need to give R,T. We will try to calibrate it. Do some rotation movement at beginning.

body_T_cam0: !!opencv-matrix # Timu2c_1 Tu2c
   rows: 4
   cols: 4
   dt: d
   data: [0.999975572679493,  0.003849141066713,  0.005854714944742, 0.0203127935529,
      -0.003828680351062,  0.999986658473099,  -0.003501944262433, -0.00510325236246,
      -0.005868115609379,  0.003479442469180,  0.999976848846595, -0.0112013882026,
      0, 0, 0, 1]

# Multiple thread support
multiple_thread: 1

# Feature traker paprameters
max_cnt: 130            # max feature number in feature tracking. It is suggested to be raised in VO mode.
min_dist: 30            # min distance between two features
freq: 10                # frequence (Hz) of publish tracking result. At least 10Hz for good estimation. If set 0, the frequence will be same as raw image
F_threshold: 2.0        # ransac threshold (pixel)
show_track: 1           # publish tracking image as topic
flow_back: 1            # perform forward and backward optical flow to improve feature tracking accuracy

# IMU acc. multiply
acc_mult: 1

# Optimization parameters
max_solver_time: 0.04   # max solver itration time (ms), to guarantee real time
max_num_iterations: 8   # max solver itrations, to guarantee real time
keyframe_parallax: 10.0 # keyframe selection threshold (pixel)

# Imu parameters       The more accurate parameters you provide, the better performance
acc_n: 0.1          # accelerometer measurement noise standard deviation. 
gyr_n: 0.01         # gyroscope measurement noise standard deviation.   
acc_w: 0.0002       # accelerometer bias random work noise standard deviation.  
gyr_w: 2.0e-5       # gyroscope bias random work noise standard deviation.     
g_norm: 9.805       # gravity magnitude

# Loop closure
loop_closure: 0                   #if you want to use loop closure to minimize the drift, set loop_closure true and give your brief pattern file path and vocabulary file path accordingly;
load_previous_pose_graph: 0       # load and reuse previous pose graph; load from 'pose_graph_save_path'
pose_graph_save_path: ""   # save and load path
save_image: 0 

# Unsynchronization parameters
estimate_td: 1                    # online estimate time offset between camera and imu
td: 0.000                         # initial value of time offset. unit: s. readed image clock + td = real image clock (IMU clock)

# Rolling shutter parameters
rolling_shutter: 1                      # 0: global shutter camera, 1: rolling shutter camera
rolling_shutter_tr: 0.033               # unit: s. rolling shutter read out time per frame (from data sheet)

# RGBD camera Ideal Range
depth_min_dist: 0.3
depth_max_dist: 3

# Structural constraints
horizontal_structural_th: 3.0
line_horizontal_structural_th: 3.0
vertical_structural_th: 2.0

# Outlier threshold
err_pt_line: 10 
err_normal_line: 10 
err_point: 20
err_plane_dist: 1.0

# Result format
save_tum: 1

# Drop frame
drop_frame: 0

# Min used num (line/point)
min_used_num: 4

# ablation study
structure_verify: 1
structure: 1
